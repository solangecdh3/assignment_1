{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/solangecdh3/assignment_1/blob/main/assignment_1/assignment_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "INkAgt-hTY_-"
      },
      "source": [
        "# Assignment 1 -  Basic Visualization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FTEAadCkTZAA"
      },
      "source": [
        "## *Solange Holman*\n",
        "Netid: sh143991\n",
        "\n",
        "Note: this assignment falls under collaboration Mode 2: Individual Assignment – Collaboration Permitted. Please refer to the syllabus on Canvas for additional information."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mzkmvTNfTZAA"
      },
      "source": [
        "Instructions for all assignments can be found [here](https://github.com/kylebradbury/ids705/blob/master/assignments/_Assignment%20Instructions.ipynb), and is also linked to from the [course syllabus](https://kylebradbury.github.io/ids705/index.html).\n",
        "\n",
        "Total points in the assignment add up to 90; an additional 10 points are allocated to presentation quality."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IAPvzGDXTZAA"
      },
      "source": [
        "#  Learning Objectives\n",
        "The purpose of this assignment is to provide practice in fundamental concepts that we will use throughout this course. By completing this assignment, you will...\n",
        "- Practice numerical programming by loading and filtering data.\n",
        "- Learn to visuzalize and perform basic statistics on the data.\n",
        "- Apply your skills altogether through an exploratory data analysis to practice data cleaning, data manipulation, interpretation, and communication\n",
        "\n",
        "We will build on these concepts throughout the course, so use this assignment as a catalyst to deepen your knowledge and seek help with anything that is unfamiliar.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ntZoXcmBTZAB"
      },
      "source": [
        "*Note: for all assignments, write out all equations and math using markdown and [LaTeX](https://tobi.oetiker.ch/lshort/lshort.pdf). For this assignment show ALL math work*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8kS629PqTZAD"
      },
      "source": [
        "**ANSWER**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zJo_2az4TZAD"
      },
      "source": [
        "# I/O and Numerical Programming"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QeMy78fGTZAD"
      },
      "source": [
        "## 1\n",
        "**[40 points]** Loading data and gathering insights from a real dataset\n",
        "\n",
        "In data science, we often need to find relevant resources and learn how to ask the appropriate questions (let's be honest....using Google) to find those resources. In this assignment you will be challenged to learn to use another Python data analysis library called `Pandas`.  This library is useful for organizing data into rows and columns making it easy to clean, analyze, and manipulate data. You've been introduced to it in class, but that challenge here it to use what you've learned so far and apply it to another new library.  Ready?? Here we go!   \n",
        "\n",
        "\n",
        "**Data**. The data for this problem can be found in two places. One is a simple install. The data can also be found in the `data` subfolder in the `assignments` folder on [github](https://github.com/lucywowen/csci591_CCN). The filename is `penguins.csv`. You'll use both to practice `pip install` and loading a csv file!\n",
        "\n",
        "\n",
        "This dataset consists of 7 columns.\n",
        "\n",
        "- species: penguin species (Chinstrap, Adélie, or Gentoo)\n",
        "- bill_length_mm: bill length (mm)\n",
        "- bill_depth_mm: bill depth (mm)\n",
        "- flipper_length_mm: flipper length (mm)\n",
        "- body_mass_g: body mass (g)\n",
        "- island: island name (Dream, Torgersen, or Biscoe) in the Palmer Archipelago (Antarctica)\n",
        "- sex: penguin sex\n",
        "\n",
        "\n",
        "\n",
        "**Your objective**. For this dataset, your goal is to follow these instructions and answer the following questions:\n",
        "\n",
        "_The following questions are work 2 points each._\n",
        "\n",
        "**(a)** Load the penguins dataset using `!pip install palmerpenguins`.  Load the library using `from palmerpenguins import load_penguins` and then load the data using `penguins = load_penguins()`.  \n",
        "\n",
        "\n",
        "**(b)** Now you have the data in a `pandas.DataFrame`! Confirm that using a function we've discussed in class.\n",
        "\n",
        "**(c)** Use a new method (look it up) to return the first 10 rows of the dataset.  \n",
        "\n",
        "**(d)** Ok, now let's try to load the data another way.  This time, try to load the data from the `data` subfolder in the `assignments` folder on [github](https://github.com/lucywowen/csci191_ProgSci/tree/main/data). The filename is `penguins.csv`.  This can be tricky!  Particularly since we're working with Colab at the moment... look up how to upload the data to Colab (there are LOTS of ways to do this!) Once you do that, import the data using `pandas.read_csv()` methods and store the data in a new variable called `penguins_uploaded`. _If this is too difficult, just use the `penguins` data from part **a** for part the remaining questions._  \n",
        "\n",
        "**(e)**  `penguins_uploaded` is the same data as `penguins` in part **a** (no trickery, I promise!) but let's check ... use the `.equals()` method to confirm that.  \n",
        "\n",
        "**(f)** Assess the missing values in the data. Return a count of the NA values by column.\n",
        "\n",
        "**(g)** Ok now return a count of the number samples for each species.  \n",
        "\n",
        "**(h)** After that, use the `.dropna()` to remove any rows with missing values and store the new cleaned dataframe as `penguins_cleaned`. Again, return a count of the number samples for each species for `penguins_cleaned`. What's the difference?\n",
        "\n",
        "**(i)** Let's do some basic stats.  Use the `.describe()` method to return some descriptive statistics on the data. If you use this method on the full dataframe, do you notice any columns that are missing?  Why do you think that is?\n",
        "\n",
        "**(j)** Convert the `body_mass_g` values from grams to kg.  \n",
        "\n",
        "**(bonus +1 point)** Convert the categorical `sex` variable to numerical and rerun the `.describe()` method.  What do you notice about the output?   \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NFX1SSqATZAD"
      },
      "source": [
        "**ANSWER**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uENxx9_VTZAD"
      },
      "source": [
        "# Visualization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "shzvGVzgTZAE"
      },
      "source": [
        "## 2\n",
        "**[40 points]** Visualization\n",
        "\n",
        "In data science, we often need to have a sense of the idiosyncrasies of the data, how they relate to the questions we are trying to answer, and to use that information to help us to determine what approach we may need to apply to achieve our goal. This exercise provides practice in exploring a dataset and answering question that might arise from applications related to the data.\n",
        "\n",
        "\n",
        "**Data**. Use the `penguins_cleaned` dataframe for the following questions\n",
        "\n",
        "\n",
        "**Your objective**. For this dataset, your goal is to follow these instructions and answer the following questions:\n",
        "\n",
        "_The following questions are work 5 points each._\n",
        "\n",
        "**(a)** Plot a bar plot of the number of samples from each species. There are a LOT of ways to do this!  Try at least 2 (for example... you can use the pandas `.plot()` method, you can use `matplotlib.pyplot`, and you can use a cool library called `seaborn`).  \n",
        "\n",
        "**(b)** On the sample plot, create boxplots for the variables: `'bill_length_mm'` `'bill_depth_mm'` `'flipper_length_mm'`.\n",
        "\n",
        "**(c)** On the sample plot, create violin plots for the variables: `'bill_length_mm'` `'bill_depth_mm'` `'flipper_length_mm'`.  How is this different from the boxplots?  What do we gain from this?\n",
        "\n",
        "**(d)** Plot a scatterplot with the `'bill_length_mm'` on the x-axis and `'bill_depth_mm'` on the y-axis, and the points colored by species.   \n",
        "\n",
        "**(bonus +1 point)**  Add regression lines by species to this scatterplot!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BASw0yPhTZAE"
      },
      "source": [
        "**ANSWER**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ip7LwEpCTZAE"
      },
      "source": [
        "# Exploratory Data Analysis\n",
        "## 3\n",
        "**[10 points]** Your goal is to explore the [datasets available](https://github.com/lucywowen/csci191_ProgSci/tree/main/data/prog_sci_data) and identify questions or problems you're interested in working with.  \n",
        "\n",
        "1. Find 2 datasets that interest you from [here](https://github.com/lucywowen/csci191_ProgSci/tree/main/data/prog_sci_data).\n",
        "\n",
        "2. For each of the 2 datasets, describe the dataset, the source of the data, and the reason the dataset was of interest. What question are you hoping to answer through exploring the dataset?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l56U-8r9TZAE"
      },
      "source": [
        "**ANSWER**"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "nteract": {
      "version": "0.28.0"
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "position": {
        "height": "643px",
        "left": "1548px",
        "right": "20px",
        "top": "121px",
        "width": "350px"
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": true
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}